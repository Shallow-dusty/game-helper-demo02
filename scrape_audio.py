import requests
from bs4 import BeautifulSoup
import os
import time
import re

# é…ç½®
BASE_URL = "https://www.soundjay.com"
OUTPUT_DIR = "downloaded_audio"
# æƒ³è¦çˆ¬å–çš„ç±»åˆ«é¡µé¢
CATEGORIES = [
    {"url": "https://www.soundjay.com/ambient-sounds.html", "name": "ambient"},
    {"url": "https://www.soundjay.com/nature-sounds.html", "name": "nature"},
    # {"url": "https://www.soundjay.com/clock-sound-effect.html", "name": "clock"}, # 404 Not Found
    {"url": "https://www.soundjay.com/magic-sound-effect.html", "name": "magic"},
]

def ensure_dir(directory):
    if not os.path.exists(directory):
        os.makedirs(directory)

def download_file(url, filepath, max_retries=3, backoff=2):
    """ä¸‹è½½éŸ³é¢‘ï¼ŒéªŒè¯ Content-Type å¹¶åœ¨ä¸´æ—¶é”™è¯¯æ—¶é‡è¯•"""
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    }
    temp_path = f"{filepath}.part"

    for attempt in range(1, max_retries + 1):
        try:
            response = requests.get(url, headers=headers, stream=True, timeout=30)
            response.raise_for_status()

            content_type = response.headers.get('Content-Type', '').lower()
            if not content_type.startswith('audio/') and not url.lower().endswith('.mp3'):
                raise ValueError(f"ééŸ³é¢‘èµ„æº(Content-Type={content_type or 'unknown'})")

            with open(temp_path, 'wb') as f:
                for chunk in response.iter_content(chunk_size=8192):
                    if chunk:
                        f.write(chunk)
            os.replace(temp_path, filepath)
            print(f"âœ… å·²ä¸‹è½½: {filepath}")
            return True
        except (requests.HTTPError, requests.ConnectionError, requests.Timeout, ValueError) as e:
            should_retry = isinstance(e, (requests.HTTPError, requests.ConnectionError, requests.Timeout)) and attempt < max_retries
            print(f"âŒ ä¸‹è½½å¤±è´¥ {url} (å°è¯• {attempt}/{max_retries}): {e}")
            if os.path.exists(temp_path):
                os.remove(temp_path)
            if should_retry:
                sleep_time = backoff ** (attempt - 1)
                print(f"â³ {sleep_time}s åé‡è¯•...")
                time.sleep(sleep_time)
            else:
                return False

    return False

def scrape_category(category):
    print(f"\nğŸ” æ­£åœ¨æ‰«æç±»åˆ«: {category['name']} ({category['url']})...")
    
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        response = requests.get(category['url'], headers=headers)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # SoundJay é€šå¸¸åœ¨ <audio> æ ‡ç­¾æˆ–é“¾æ¥ä¸­æä¾› mp3
        # æŸ¥æ‰¾æ‰€æœ‰ mp3 é“¾æ¥
        audio_links = []
        
        # ç­–ç•¥1: æŸ¥æ‰¾ href ç»“å°¾æ˜¯ .mp3 çš„ a æ ‡ç­¾
        for a in soup.find_all('a', href=True):
            href = a['href']
            if href.endswith('.mp3'):
                full_url = href if href.startswith('http') else f"{BASE_URL}/{href}"
                # è·å–æè¿°æ–‡æœ¬
                desc = a.get_text(strip=True)
                if not desc:
                    # å°è¯•æ‰¾å‰ä¸€ä¸ªå…„å¼ŸèŠ‚ç‚¹çš„æ–‡æœ¬
                    prev = a.find_previous('div')
                    if prev:
                        desc = prev.get_text(strip=True)
                
                audio_links.append({'url': full_url, 'desc': desc or 'unknown'})

        # å»é‡
        unique_links = {v['url']: v for v in audio_links}.values()
        
        print(f"ğŸ“Š æ‰¾åˆ° {len(unique_links)} ä¸ªéŸ³é¢‘æ–‡ä»¶")
        
        category_dir = os.path.join(OUTPUT_DIR, category['name'])
        ensure_dir(category_dir)
        
        for item in unique_links:
            url = item['url']
            filename = url.split('/')[-1]
            filepath = os.path.join(category_dir, filename)
            
            if os.path.exists(filepath):
                print(f"â­ï¸ è·³è¿‡å·²å­˜åœ¨: {filename}")
                continue
                
            print(f"â¬‡ï¸ æ­£åœ¨ä¸‹è½½: {filename}...")
            download_file(url, filepath)
            time.sleep(1) # ç¤¼è²Œçˆ¬å–ï¼Œé¿å…è¯·æ±‚è¿‡å¿«
            
    except Exception as e:
        print(f"âŒ å¤„ç†ç±»åˆ« {category['name']} æ—¶å‡ºé”™: {e}")

def main():
    print("ğŸµ å¼€å§‹çˆ¬å– SoundJay éŸ³é¢‘èµ„æº...")
    ensure_dir(OUTPUT_DIR)
    
    for cat in CATEGORIES:
        scrape_category(cat)
        
    print("\nâœ¨ æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼éŸ³é¢‘å·²ä¿å­˜åœ¨ downloaded_audio ç›®å½•ä¸­ã€‚")
    print("ğŸ’¡ æç¤º: ä½ å¯ä»¥å°†ä¸‹è½½çš„éŸ³é¢‘ä¸Šä¼ åˆ° CDN æˆ–é¡¹ç›® public ç›®å½•ï¼Œå¹¶åœ¨ constants.ts ä¸­æ›´æ–° URLã€‚")

if __name__ == "__main__":
    main()
